{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from functions import getinfo\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapeamos los supermercados.\n",
    "supermercados_scrap = ['mercadona','dia','lidl','carrefour']\n",
    "for super in supermercados_scrap:\n",
    "    getinfo(super,'key')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porcion\n",
      "Kcal\n",
      "Grasa\n",
      "Grasas saturadas\n",
      "Carbohidratos\n",
      "Azucares\n",
      "Proteina\n",
      "Sal\n"
     ]
    }
   ],
   "source": [
    "'''#Añadimos los productos que dieron error porque nos quedamos sin créditos\n",
    "productos = ['Bebida +Proteínas Sabor Coco', 'Atún en Aceite de Oliva', 'Patatas Chips',\n",
    "    'Costillas de Cerdo Asadas', 'Pan de Molde sin Gluten', 'Hélices Vegetales',\n",
    "    'Café Soluble Descafeinado', 'Chocolate Extrafino Negro 85% Cacao',\n",
    "    'Barquillos Artesanos', 'Ternera al Ajillo', 'Yogur para Beber 0 Fresa']\n",
    "porcion = ['100g', '60g', '100g', '100g', '100g', '100g', '2g', '20g', '100g', '100g', '100g']\n",
    "kcal = ['48', '147', '506', '257', '282', '358', '5', '115', '401', '98', '31']\n",
    "grasa = ['0.4', '10.8', '27.2', '15', '11', '1.5', '0', '9.2', '6.3', '2', '0.1']\n",
    "grasa_saturada = ['0.2', '1.740', '3.9', '5.8', '1.3', '0.3', '0', '5.6', '1.9', '0.8', '0']\n",
    "carbs = ['3.8', '0.54', '58', '16', '40', '72', '0.76', '4.3', '79', '1.5', '4.2']\n",
    "azucar = ['3.5', '0.30', '1.6', '12', '3.8', '3.1', '0', '3.0', '39', '0.5', '4.1']\n",
    "prote = ['7.2', '12.6', '7.3', '14', '1', '12', '0.34', '2.4', '7', '19', '3.2']\n",
    "sal = ['0.12', '0', '0.01', '1.2', '1.3', '0.03', '0', '0', '0', '1.3', '0']\n",
    "productos_fallo = pd.DataFrame({\n",
    "    'Producto': productos,\n",
    "    'Porcion': porcion,\n",
    "    'Kcal': kcal,\n",
    "    'Grasa': grasa,\n",
    "    'Grasas saturadas': grasa_saturada,\n",
    "    'Carbohidratos': carbs,\n",
    "    'Azucares': azucar,\n",
    "    'Proteina': prote,\n",
    "    'Sal': sal\n",
    "})\n",
    "productos = ['Jamon serrano reserva','Choco Galleta-Biscoito','Frito Mallorquin']\n",
    "porcion = ['100g','100g','100g']\n",
    "kcal = ['248','501','122']\n",
    "grasa = ['12.2','25','3.9']\n",
    "grasa_saturada = ['4.6','14','1.9']\n",
    "carbs = ['1','64','2.7']\n",
    "azucar = ['0.5','45','0.9']\n",
    "prote = ['33.5','5.1','18.9']\n",
    "sal = ['3.6','0.44','0.37']\n",
    "\n",
    "productos_fallodos = pd.DataFrame({\n",
    "    'Producto': productos,\n",
    "    'Porcion': porcion,\n",
    "    'Kcal': kcal,\n",
    "    'Grasa': grasa,\n",
    "    'Grasas saturadas': grasa_saturada,\n",
    "    'Carbohidratos': carbs,\n",
    "    'Azucares': azucar,\n",
    "    'Proteina': prote,\n",
    "    'Sal': sal\n",
    "})\n",
    "'''\n",
    "\n",
    "#Cargamos todos los dataframe:\n",
    "Datamerca = pd.read_csv('Dataset/Dismissed Data/Scrap_Mercadona.csv')\n",
    "DataCrf = pd.read_csv('Dataset/Dismissed Data/Scrap_CRF.csv')\n",
    "DataDia = pd.read_csv('Dataset/Dismissed Data/Scrap_DIA.csv')\n",
    "DataLidl = pd.read_csv('Dataset/Dismissed Data/Scrap_LILD.csv')\n",
    "\n",
    "\n",
    "\n",
    "#Añadimos columna en cada Dataframe con su supermercado.\n",
    "Datamerca['Supermercado'] = 'Mercadona'\n",
    "DataLidl['Supermercado'] = 'Lidl'\n",
    "DataDia['Supermercado'] = 'Dia'\n",
    "DataCrf['Supermercado'] = 'Carrefour'\n",
    "\n",
    "#Juntamos Dataframe, reseteamos index y dropeamos las columnas que generaron fallo.\n",
    "data = pd.concat([Datamerca, DataCrf, DataDia, DataLidl])\n",
    "data.reset_index(inplace = True, drop = True)\n",
    "data.dropna(inplace = True)\n",
    "\n",
    "#Quitamos todas las 'g'\n",
    "#Subst los - por 0.\n",
    "#pasamos a número\n",
    "cols = list(data.columns)\n",
    "cols\n",
    "for i in cols[1:-1]:\n",
    "    print(i)\n",
    "    data[i] = data[i].str.replace('g', '')\n",
    "    data[i] = data[i].str.replace('kcal','')\n",
    "    data[i] = data[i].str.replace(',','.')\n",
    "    data[i] = data[i].str.replace('-','0')\n",
    "    data[i] = data[i].str.replace(' ','')\n",
    "    data[i] = data[i].str.replace('ml','')\n",
    "\n",
    "#Como hay porciones que son 1Galleta(25g) - nos quedamos con lo que hay entre parentesis i como hemos quitado los g pues ya lo tenemos.\n",
    "porcion_num = []\n",
    "for i in data['Porcion']:\n",
    "    \n",
    "    parentesis = re.search('\\((.*?)\\)',i)\n",
    "    if parentesis:\n",
    "        porcion_num.append(parentesis.group(1))\n",
    "    else:\n",
    "        porcion_num.append(i)\n",
    "\n",
    "data['Porcion'] = porcion_num\n",
    "\n",
    "\n",
    "#Sigue habiendo productos de los que no tenemos la info correcta: chekiamos cuales son\n",
    "ture = []\n",
    "for i in data['Porcion']:\n",
    "    \n",
    "    letras = re.search('\\d\\D\\D|\\D\\D',i)\n",
    "    if letras:\n",
    "        ture.append(True)\n",
    "    else:\n",
    "        ture.append(False)\n",
    "\n",
    "data['Porcion_check'] = ture\n",
    "\n",
    "#Como son pocos, los cambiamos manualmente:\n",
    "cols\n",
    "for i in cols[1:-1]:\n",
    "    data[i] = data[i].str.replace('escurrido', '52')\n",
    "    data[i] = data[i].str.replace('escurrida', '62')\n",
    "    data[i] = data[i].str.replace('1helado', '70')\n",
    "    data[i] = data[i].str.replace('1porción','100')\n",
    "    data[i] = data[i].str.replace('4unidades','100')\n",
    "    data[i] = data[i].str.replace('4alletas','44')\n",
    "    data[i] = data[i].str.replace('1unidad','100')\n",
    "    data[i] = data[i].str.replace('2alletas','35')\n",
    "    data[i] = data[i].str.replace('5alletas','55')\n",
    "    data[i] = data[i].str.replace('1barrita','25')\n",
    "    data[i] = data[i].str.replace('100oz','100')\n",
    "    data[i] = data[i].str.replace('2tortitas','25')\n",
    "    data[i] = data[i].str.replace('2unidades','32')\n",
    "    data[i] = data[i].str.replace('3barritas','50')\n",
    "\n",
    "\n",
    "#Ponemos en float los datos que nos interesan:\n",
    "data.drop(columns='Porcion_check', inplace = True)\n",
    "for i in cols[1:-1]:\n",
    "    data[i] = data[i].astype(float)\n",
    "\n",
    "#Convertimos todo a porcion 100g:\n",
    "cols = list(data.columns)[2:-1]\n",
    "for i in cols:\n",
    "    data[i] = (data[i]/data['Porcion'])*100\n",
    "data.drop(columns='Porcion', inplace = True) \n",
    "#Y nos cargamos la columna porción porque no nos hace falta más.\n",
    "\n",
    "#Hay que quitar productos \"Duplicados\" hay varios productos con el mismo nombre en el mismo supermercado. Los hay que elminiar\n",
    "dupli = data.duplicated(subset=['Producto','Supermercado'], keep = 'first')\n",
    "dupli\n",
    "\n",
    "data = data[~dupli]\n",
    "\n",
    "#Guardamos el DataSet limpio por si las moscas:\n",
    "data.to_excel(f'Dataset/Data.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.drop(data[data['Porcion_check'] == True].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Kcal'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.drop(columns='Porcion_check', inplace = True)\n",
    "cols = list(data.columns)[2:-1]\n",
    "for i in cols:\n",
    "    data[i] = (data[i]/data['Porcion'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('Dataset/Data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Con el dataset total hacemos un KNN:\n",
    "x=data[list(data.columns)[1:-1]]\n",
    "scaler=StandardScaler()\n",
    "x_prep=scaler.fit_transform(x)\n",
    "\n",
    "K=range(2, 20)\n",
    "inertia=[]\n",
    "for k in K:\n",
    "    kmeans=KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(x_prep)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, inertia, \"bx-\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"inertia\")\n",
    "plt.xticks(np.arange(min(K), max(K)+1, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diferenciamos dos codos, uno en el 6 y el otro en el 11\n",
    "\n",
    "![](Images\\Codo_dataset_con_sal_y_totales.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El 6 nos crea clústers demasiado generales. Así como tenemos los datos planteados nos interesa dividir bastante la muestra\n",
    "#Con 11 clúster, los clúster están mejor pero hay un clúster que son productos con mucha sal que solo tiene 5 productos\n",
    "kmeans = KMeans(n_clusters=11, random_state=123)\n",
    "kmeans.fit(x_prep)\n",
    "cluster = kmeans.predict(x_prep)\n",
    "data['Cluster_Kmeans'] = cluster\n",
    "\n",
    "data.Cluster_Kmeans.value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Images\\Clsuter_con_sal_y_totales_11_cluster.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probando con otros números de cluster la sal siempre tiene mucha importancia dentro de algún cluster y no me interesa que sea tan decisivio. \n",
    "\n",
    "#Quitamos la sal y nos salen mejor los cluster:\n",
    "data.drop(columns='Sal', inplace = True)\n",
    "x=data[list(data.columns)[1:-1]]\n",
    "scaler=StandardScaler()\n",
    "x_prep=scaler.fit_transform(x)\n",
    "\n",
    "K=range(2, 20)\n",
    "inertia=[]\n",
    "for k in K:\n",
    "    kmeans=KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(x_prep)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, inertia, \"bx-\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"inertia\")\n",
    "plt.xticks(np.arange(min(K), max(K)+1, 1.0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](Images\\Codo_dataset_sin_sal_y_totales.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probamos con 7 codos y nos quedan unos clúster bastante acertados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos una funcion para poder comprobar cuáles son las predicciones para algunos productos y hacer pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hacer un VIF para la correlacion entre variables (Quitamos Kcal?)\n",
    "corraus = data.drop(columns = ['Producto', 'Supermercado']).corr()\n",
    "mask = np.triu(np.ones_like(corraus, dtype=bool))\n",
    "corr_var = sns.heatmap(corraus,annot=True,mask=mask)\n",
    "plt.title(\"Correlación\")\n",
    "plt.show()\n",
    "#Kcal esta bastante correlacionado con la variable grasas y Carbohidratos. Probaremos hacer el KNN sin ella.\n",
    "\n",
    "\n",
    "#Probar otros modelos\n",
    "\n",
    "#Probar como predice con los datos porcentuales. \n",
    "data['Saturada%'] = data['Grasas saturadas']/data['Grasa']*100\n",
    "data['Azucares%'] = data['Azucares']/data['Carbohidratos']*100\n",
    "\n",
    "data.drop(columns=['Azucares', 'Grasas saturadas'], inplace = True)\n",
    "data_numeric = data.apply(pd.to_numeric, errors = 'coerce')\n",
    "masca = np.isinf(data_numeric).any(axis=1)\n",
    "\n",
    "infinitos = data_numeric[masca]\n",
    "infinitos\n",
    "\n",
    "data.replace([np.inf, -np.inf], 0, inplace=True)\n",
    "data = data.fillna(0)\n",
    "\n",
    "#Hacer clúster de clústers? -->Así organizamos según macronutrientes y dentro de estos distinguimos tendencias. \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
